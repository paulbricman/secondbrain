I";<p>If <a class="internal-link" href="/secondbrain/language-models-are-few-shot-learners">language models</a> output either very high-likelihood or very low-likelihood <a class="internal-link" href="/secondbrain/written-word-is-a-proxy-for-thought">completions</a>, they are rated as worse by <a class="internal-link" href="/secondbrain/human-api-pushes-crowdsourcing-on-the-tech-stack">humans</a>. There seems to be a sweet spot of desired <a class="internal-link" href="/secondbrain/perplexity-estimation-enables-antifragile-learning">likelihood</a> in <a class="internal-link" href="/secondbrain/few-shot-learning-exapts-text-generation">text</a>. This is <a class="internal-link" href="/secondbrain/sublime-is-a-tool-against-motivated-reasoning">likely</a> true for machine-generated text as well as human-written text.</p>
:ET