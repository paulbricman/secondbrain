I"]<p>By representing a <span title="There is no note that matches this link." class="invalid-link">
  <span class="invalid-link-brackets">[[</span>
  Tokenization for i+1 language learning is non-trivial|token
  <span class="invalid-link-brackets">]]</span></span> at multiple levels of abstraction concurrently, <a class="internal-link" href="/secondbrain/attention-is-representational-resource-allocation">from the fine structure to the coarse one, one can derive hierarchical representations</a>. Elements which have <a class="internal-link" href="/secondbrain/sum-of-elements-represents-their-set-in-hyperdimensional-computing">a lot in common</a> at coarse levels might be on the same branch, only to break off at a finer level. This approach might enable consequential explanations in <a class="internal-link" href="/secondbrain/perception-is-context-dependent">perception</a>, <a class="internal-link" href="/secondbrain/memory-is-perception-of-structural-artifacts">memory</a>, and <a class="internal-link" href="/secondbrain/discrete-structure-embeddings-in-continuous-space-are-glitchy">intelligence</a>.</p>
:ET