I"K<table>
  <tbody>
    <tr>
      <td>While the L1, L2 norms, and p-norm in general are [[Optimizing for short semantic distances fosters learning</td>
      <td>distance functions]] which take into consideration the magnitude of the two [[One-hot encodings are basis vectors in type space</td>
      <td>vectors]] involved, the cosine similarity only indicates how aligned are the two, regardless of their magnitude. Cosine similarity is the default choice in [[Multi-lingual embeddings formalize geography of thought</td>
      <td>word embeddings]].</td>
    </tr>
  </tbody>
</table>
:ET