I"%<table>
  <tbody>
    <tr>
      <td>Just like many see [[Attention is a competition</td>
      <td>attention as a competition of stimuli]], attention can also be seen as the process of [[Mental representations connect internal with external state</td>
      <td>representational resource]] allocation. In this view, attention would be the [[Premotor theory of attention is fundamentally enactive</td>
      <td>enactive]] process of [[Representationism in cognition is adaptationism in evolution</td>
      <td>representing]] the world in a differentially rich fashion. [[Dynamic attention enables object permanence</td>
      <td>Attended stimuli]] would have [[Isomorphic representations partially preserve structure</td>
      <td>their structure better preserved, more of their variance would be explained]]. This model of attention is deeply compatible with the formalisms of attention used in [[Supervised learning assumes underlying structure</td>
      <td>machine learning]], such as self-attention in transformers.</td>
    </tr>
  </tbody>
</table>
:ET