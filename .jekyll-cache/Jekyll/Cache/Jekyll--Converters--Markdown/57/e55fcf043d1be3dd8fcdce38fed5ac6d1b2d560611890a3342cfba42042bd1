I"È<table>
  <tbody>
    <tr>
      <td>If [[Language models are few-shot learners</td>
      <td>language models]] output either very high-likelihood or very low-likelihood [[Written word is a proxy for thought</td>
      <td>completions]], they are rated as worse by [[Human API pushes crowdsourcing on the tech stack</td>
      <td>humans]]. There seems to be a sweet spot of desired [[Perplexity estimation enables antifragile learning</td>
      <td>likelihood]] in [[Few-shot learning exapts text generation</td>
      <td>text]]. This is [[Sublime is a tool against motivated reasoning</td>
      <td>likely]] true for machine-generated text as well as human-written text.</td>
    </tr>
  </tbody>
</table>
:ET