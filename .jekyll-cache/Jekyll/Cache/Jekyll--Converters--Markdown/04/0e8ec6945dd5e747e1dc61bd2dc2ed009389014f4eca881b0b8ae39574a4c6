I"€<p>Due to their <a class="internal-link" href="/secondbrain/recurrent-networks-approximate-dynamical-systems">recurrent nature</a>, <a class="internal-link" href="/secondbrain/backpropagation-through-time-makes-rnns-feasible">the parameters of RNNs</a> are changed proportional to a partial derivative which is exponential. If larger than one, it often explodes with <a class="internal-link" href="/secondbrain/backpropagation-through-time-makes-rnns-feasible">long considered sequences</a>. If smaller than one, it often vanishes. <a class="internal-link" href="/secondbrain/lstms-mitigate-rnn-issues">LSTMs attempt to solve this</a>.</p>
:ET