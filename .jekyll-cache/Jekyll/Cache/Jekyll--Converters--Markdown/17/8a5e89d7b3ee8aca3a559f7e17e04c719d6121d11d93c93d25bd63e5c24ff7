I"Ÿ<table>
  <tbody>
    <tr>
      <td>LSTMâ€™s mitigate some of the issues of [[Recurrent networks approximate dynamical systems</td>
      <td>RNNâ€™s]], namely the [[Vanilla RNNâ€™s often run into vanishing and exploding gradients</td>
      <td>vanishing and exploding gradients]], by introducing some specialized neural ensembles. Through three gates (i.e. input, forget, output), the [[Dynamical systems have a certain anatomy</td>
      <td>representations]] stored in the [[Recurrent networks approximate dynamical systems</td>
      <td>RNN]] are carefully modulated [[Dynamical systems have memory</td>
      <td>across time]].</td>
    </tr>
  </tbody>
</table>
:ET