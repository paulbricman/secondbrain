I"‘<table>
  <tbody>
    <tr>
      <td>As [[Supervised learning assumes underlying structure</td>
      <td>supervised learning is used to approximate an underlying mapping]] across spaces with higher and higher dimensionality, the [[Supervised learning is argmin in hypothesis space of model architecture</td>
      <td>model]] becomes more and more prone to [[Machine learning models have fluid and crystallized intelligence</td>
      <td>overfitting]]. Specific tricks like [[Regularization penalizes flexibility</td>
      <td>regularization and adapting model flexibility]] are used to tackle this Lovecraftian issue.</td>
    </tr>
  </tbody>
</table>
:ET