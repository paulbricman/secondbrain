I"O<p>In machine learning, <a class="internal-link" href="/secondbrain/semantic-embeddings-of-discrete-items-are-like-checkers">semantic embeddings of discrete items</a> can either denote <a class="internal-link" href="/secondbrain/prototypical-reasoning-enriches-exemplars">prototypes or exemplars</a> of <a class="internal-link" href="/secondbrain/family-resemblance-glues-exemplars-into-fuzzy-concepts">conceptual families</a>. When denoting <a class="internal-link" href="/secondbrain/classes-are-prototypes-objects-are-exemplars">prototypes</a>, they are <a class="internal-link" href="/secondbrain/deep-learning-is-consonant-with-empiricism">informed by exemplars</a>. In this, machine learning tacitly embraces the concept theory assumption that <a class="internal-link" href="/secondbrain/concept-learning-is-few-shot-scaffolding-supported-by-working-memory">concept learning</a> consists on deriving prototypes based on exemplars in <a class="internal-link" href="/secondbrain/context-independent-strategies-are-like-good-chess-moves">context</a>. However, when denoting <a class="internal-link" href="/secondbrain/exemplar-search-results-in-gradually-less-representative-items">exemplars</a>, each token gets its own <a class="internal-link" href="/secondbrain/context-independent-strategies-are-like-good-chess-moves">context-based embedding</a>.</p>
:ET