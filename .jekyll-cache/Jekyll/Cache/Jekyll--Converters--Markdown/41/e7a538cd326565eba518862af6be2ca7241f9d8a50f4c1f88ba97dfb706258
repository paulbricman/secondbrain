I"¾<p>In forward-mode differentiation, computing the partial derivative of <a class="internal-link" href="/secondbrain/deep-learning-enables-simple-chained-transformations">one node in a computational graph</a> would require computing the partial derivatives for all nodes in the graph, making a single step in <a class="internal-link" href="/secondbrain/end-to-end-differentiation-enables-powerful-optimization-techniques">gradient descent</a> extremely computationally expensive. In contrast, in reverse-mode differentiation, which supports backpropagation, computing the partial derivative of all nodes can be done in one single sweep, by starting with the partial derivatives of the output nodes.</p>
:ET