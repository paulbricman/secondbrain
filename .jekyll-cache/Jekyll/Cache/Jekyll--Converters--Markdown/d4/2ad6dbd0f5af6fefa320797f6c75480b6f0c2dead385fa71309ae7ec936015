I"Œ<table>
  <tbody>
    <tr>
      <td>Not only is most of machine learning [[Machine learning is interpolative</td>
      <td>interpolative]] and therefore limited in generalization, but it is often not well suited for manipulating [[Finite-state dynamical systems are diverse</td>
      <td>discrete structures]]. Just like a Fourier series approximates a square signal with glitches caused (i.e. Gibbs phenomenon), [[Deep learning is consonant with empiricism</td>
      <td>neural networks]] are brittle when [[Mental representations connect internal with external state</td>
      <td>representing]] discrete discontinuous structures. However, one could argue that the [[Manifolds formalize emergence</td>
      <td>brain]] supports a [[Phenomenal space is adaptive</td>
      <td>continuous mental and phenomenal space]], which sometimes approximates discrete systems.</td>
    </tr>
  </tbody>
</table>
:ET