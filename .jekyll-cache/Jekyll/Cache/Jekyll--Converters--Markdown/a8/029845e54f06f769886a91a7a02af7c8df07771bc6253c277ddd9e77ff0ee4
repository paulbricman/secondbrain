I"©<table>
  <tbody>
    <tr>
      <td>LSTMs mitigate some of the issues of [[Recurrent networks approximate dynamical systems</td>
      <td>RNNs]], namely the [[Vanilla RNNs often run into vanishing and exploding gradients</td>
      <td>vanishing and exploding gradients]], by introducing some specialized neural ensembles. Through three gates (i.e. input, forget, output), the [[Dynamical systems have a certain anatomy</td>
      <td>representations]] stored in the [[Recurrent networks approximate dynamical systems</td>
      <td>RNN]] are carefully modulated [[Dynamical systems have memory</td>
      <td>across time]]. The input gate controls the influence of the input on memory, the output gate controls how much of the memory is written to output, and the forget gate controls [[Short-long term is a spectrum for memory</td>
      <td>how much of the memory is preserved]] to the next step.</td>
    </tr>
  </tbody>
</table>
:ET