I"’<table>
  <tbody>
    <tr>
      <td>More often than not, a machine learning model is tasked with approximating a mapping based on the entirety of the available data. In contrast, people first learn in steps, gradually, progressive. They donâ€™t attempt to write eloquent English before learning to connect high-frequency words. However, the key to [[Self-supervised learning approximates commonsense</td>
      <td>developing commonsense]] might be to incrementally [[Concept learning is few-shot scaffolding supported by working memory</td>
      <td>constructively anchor new concepts on previously internalized ones]].</td>
    </tr>
  </tbody>
</table>
:ET