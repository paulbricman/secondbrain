I"Ö<table>
  <tbody>
    <tr>
      <td>The [[Boltzmann machine is a universal learning machine</td>
      <td>Boltzmann]] [[KL-divergence formalizes difference between discrete probability distributions</td>
      <td>distribution]] is a [[Joint, marginal, and conditional probabilities are primitives of probability theory</td>
      <td>probability]] distribution of [[Dynamical systems have a certain anatomy</td>
      <td>microstates]] determined by the observed macrostate and the energies of microstates. For example, the Boltzmann distribution offers a probability distribution over the possible states of a gas in a container (i.e. location &amp; momentum of each [[Particle systems populate spaces with object instances</td>
      <td>particle]]) given an observed temperature and knowledge about energies of possible microstates. Itâ€™s a physics-flavored [[Argmin and argmax formalize optimization</td>
      <td>optimization problem]].</td>
    </tr>
  </tbody>
</table>
:ET