I"Ñ<p>If you have a <a class="internal-link" href="/secondbrain/curse-of-dimensionality-hinders-high-dimensional-mappings">high-dimensional</a> probability density function, itâ€™s difficult to sample independent and identically distributed values from from it. However, itâ€™s feasible to use <a class="internal-link" href="/secondbrain/finite-state-dynamical-systems-are-diverse">Markiv chain</a> Monte Carlo <a class="internal-link" href="/secondbrain/selectively-sampling-dimensions-facilitates-manifold-definition">sampling</a>. MCMC sampling consists of <a class="internal-link" href="/secondbrain/continuous-state-dynamical-systems-share-a-common-structure">a stochastic â€œwalkâ€</a> across the population space, where <a class="internal-link" href="/secondbrain/short-long-term-is-a-spectrum-for-memory">the next sample is determined by the previous one</a>. After an extensive number of â€œsteps,â€ the sampling density becomes a more and more accurate proxy for the <a class="internal-link" href="/secondbrain/joint-marginal-and-conditional-probabilities-are-primitives-of-probability-theory">probability</a> <a class="internal-link" href="/secondbrain/backpropagation-renders-gradient-descent-feasible">landscape</a>.</p>
:ET