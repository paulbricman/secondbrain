I"Z<table>
  <tbody>
    <tr>
      <td>If the [[Risk is statistical expectation of loss</td>
      <td>risk function]] is differentiable (i.e. NOT only the model itself), as it is often the case in [[Supervised learning assumes underlying structure</td>
      <td>machine learning]], then [[Momentum in optimization is trend observation in retrospective futurism</td>
      <td>optimization]] can be performed by gradient descent. Essentially, the model parameters are tweaked so that the [[Risk is statistical expectation of loss</td>
      <td>risk]] gets minimized.</td>
    </tr>
  </tbody>
</table>
:ET