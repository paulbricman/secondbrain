I"<table>
  <tbody>
    <tr>
      <td>Each [[Eigenvectors are scaled by eigenvalues in linear transformation</td>
      <td>linear transformation]] can be expressed as a matrix. The column vectors of the matrix stand for the new locations of the [[One-hot encodings are basis vectors in type space</td>
      <td>initial basis vectors]]. Matrices capture most parameters of a linear layer in [[Supervised learning assumes underlying structure</td>
      <td>supervised learning]].</td>
    </tr>
  </tbody>
</table>
:ET