I"È<p>As <a class="internal-link" href="/secondbrain/supervised-learning-assumes-underlying-structure">supervised learning is used to approximate an underlying mapping</a> across spaces with higher and higher dimensionality, the <a class="internal-link" href="/secondbrain/supervised-learning-is-argmin-in-hypothesis-space-of-model-architecture">model</a> becomes more and more prone to <a class="internal-link" href="/secondbrain/machine-learning-models-have-fluid-and-crystallized-intelligence">overfitting</a>. Specific tricks like <a class="internal-link" href="/secondbrain/regularization-penalizes-flexibility">regularization and adapting model flexibility</a> are used to tackle this Lovecraftian issue.</p>
:ET