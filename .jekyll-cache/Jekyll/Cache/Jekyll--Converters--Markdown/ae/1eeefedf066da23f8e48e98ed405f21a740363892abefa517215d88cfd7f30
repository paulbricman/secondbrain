I"•<table>
  <tbody>
    <tr>
      <td>[[Supervised learning assumes underlying structure</td>
      <td>AI]] can be seen as â€œliving in superhistoryâ€ instead of â€œembodying superintelligence.â€ This view argues that the occasional superhuman performance of [[Language models are few-shot learners</td>
      <td>ML models]] is caused by enormous amounts of accumulated [[Experientialism breaks the subjectivism-objectivism dichotomy</td>
      <td>experience]] in a short amount of time. AlphaGo was trained on millennia of gameplay, so its â€œdata ageâ€ is orders of magnitude larger than its absolute age. By [[Few-shot learning exapts text generation</td>
      <td>exapting]] [[Spatial metaphors provide primitives for latent space navigation</td>
      <td>latent representations]], people might be able to also reap the benefits, and learn at a rate of decades per week.</td>
    </tr>
  </tbody>
</table>
:ET