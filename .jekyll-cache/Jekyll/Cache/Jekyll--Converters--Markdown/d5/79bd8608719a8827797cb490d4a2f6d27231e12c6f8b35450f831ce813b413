I"3<table>
  <tbody>
    <tr>
      <td>A simple way to force a machine learning model to derive a meaningful representation about the world it lives in is by tasking it to predict the short-term future. If a model successfully manages to predict how its environment unfolds in the future, then it plausibly learned a great deal about its inner workings. This can be seen as a [[Self-supervised learning approximates commonsense</td>
      <td>self-supervised learning paradigm]], together with [[Recovery and matching provide self-supervised signals</td>
      <td>recovery and matching]]. Additionally, attempting to predict oneâ€™s behavior might lead to a meaningful representation of their [[Digital twins expose physical objects to digital manipulations</td>
      <td>behavior]].</td>
    </tr>
  </tbody>
</table>
:ET