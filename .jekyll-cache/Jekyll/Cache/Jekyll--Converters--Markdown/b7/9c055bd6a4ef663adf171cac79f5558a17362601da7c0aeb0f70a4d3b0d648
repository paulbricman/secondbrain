I"<p>By unfolding a <a class="internal-link" href="/secondbrain/recurrent-networks-approximate-dynamical-systems">recurrent neural network</a> into a <a class="internal-link" href="/secondbrain/feedforward-networks-approximate-functions">feedforward one</a> using a clone for each time point, an engineer can apply <a class="internal-link" href="/secondbrain/backpropagation-renders-gradient-descent-feasible">backpropagation to RNNs</a>. This makes the infamously difficult to train models somewhat easier to train. However, there are drawbacks. For instance, only a certain number of time points can be considered in the unrolled network, limiting the ability of RNNs to <a class="internal-link" href="/secondbrain/dynamical-systems-have-memory">learn memory effects</a>.</p>
:ET