I"‰<p>Due to their <a class="internal-link" href="/secondbrain/recurrent-networks-approximate-dynamical-systems">recurrent nature</a>, <a class="internal-link" href="/secondbrain/backpropagation-through-time-makes-rnn-s-feasible">the parameters of RNNâ€™s</a> are changed proportional to a partial derivative which is exponential. If larger than one, it often explodes with <a class="internal-link" href="/secondbrain/backpropagation-through-time-makes-rnn-s-feasible">long considered sequences</a>. If smaller than one, it often vanishes. <a class="internal-link" href="/secondbrain/lstm-s-mitigate-rnn-issues">LSTMâ€™s attempt to solve this</a>.</p>
:ET