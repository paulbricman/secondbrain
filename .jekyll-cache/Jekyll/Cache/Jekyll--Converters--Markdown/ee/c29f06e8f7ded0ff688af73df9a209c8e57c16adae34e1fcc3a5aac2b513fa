I"ƒ<table>
  <tbody>
    <tr>
      <td>In machine learning, [[Semantic embeddings of discrete items are like checkers</td>
      <td>semantic embeddings of discrete items]] can either denote [[Prototypical reasoning enriches exemplars</td>
      <td>prototypes or exemplars]] of [[Family resemblance glues exemplars into fuzzy concepts</td>
      <td>conceptual families]]. When denoting [[Classes are prototypes, objects are exemplars</td>
      <td>prototypes]], they are [[Deep learning is consonant with empiricism</td>
      <td>informed by exemplars]]. In this, machine learning tacitly embraces the concept theory assumption that [[Concept learning is few-shot scaffolding supported by working memory</td>
      <td>concept learning]] consists on deriving prototypes based on exemplars in [[Context-independent strategies are like good chess moves</td>
      <td>context]]. However, when denoting [[Exemplar search results in gradually less representative items</td>
      <td>exemplars]], each token gets its own [[Context-independent strategies are like good chess moves</td>
      <td>context-based embedding]].</td>
    </tr>
  </tbody>
</table>
:ET