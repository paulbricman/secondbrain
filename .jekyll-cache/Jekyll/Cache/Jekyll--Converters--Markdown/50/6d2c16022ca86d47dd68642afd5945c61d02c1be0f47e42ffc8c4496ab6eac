I"¶<p>Just like many see <a class="internal-link" href="/secondbrain/attention-is-a-competition">attention as a competition of stimuli</a>, attention can also be seen as the process of <a class="internal-link" href="/secondbrain/mental-representations-connect-internal-with-external-state">representational resource</a> allocation. In this view, attention would be the <a class="internal-link" href="/secondbrain/premotor-theory-of-attention-is-fundamentally-enactive">enactive</a> process of <a class="internal-link" href="/secondbrain/representationism-in-cognition-is-adaptationism-in-evolution">representing</a> the world in a differentially rich fashion. <a class="internal-link" href="/secondbrain/dynamic-attention-enables-object-permanence">Attended stimuli</a> would have <a class="internal-link" href="/secondbrain/isomorphic-representations-partially-preserve-structure">their structure better preserved, more of their variance would be explained</a>. This model of attention is deeply compatible with the formalisms of attention used in <a class="internal-link" href="/secondbrain/supervised-learning-assumes-underlying-structure">machine learning</a>, such as self-attention in transformers.</p>
:ET