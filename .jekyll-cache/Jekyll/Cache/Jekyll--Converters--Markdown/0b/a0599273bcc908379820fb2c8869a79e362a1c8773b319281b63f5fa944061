I"ò<p>LSTMâ€™s mitigate some of the issues of <a class="internal-link" href="/secondbrain/recurrent-networks-approximate-dynamical-systems">RNNâ€™s</a>, namely the <a class="internal-link" href="/secondbrain/vanilla-rnn-s-often-run-into-vanishing-and-exploding-gradients">vanishing and exploding gradients</a>, by introducing some specialized neural ensembles. Through three gates (i.e. input, forget, output), the <a class="internal-link" href="/secondbrain/dynamical-systems-have-a-certain-anatomy">representations</a> stored in the <a class="internal-link" href="/secondbrain/recurrent-networks-approximate-dynamical-systems">RNN</a> are carefully modulated <a class="internal-link" href="/secondbrain/dynamical-systems-have-memory">across time</a>.</p>
:ET