---
resource: https://doi.org/10.1111/phc3.12625
---

The tradition of symbolic AI attempted to formalize intelligence as symbol manipulation. On the other hand, connectionist AI attempted to do that through neural networks, using no explicit symbols. Empiricism, as opposed to nativism, argues that a mind has no prior knowledge about the world prior to observing it, it's tabula rasa. Deep learning can be viewed as empiricism because models are trained on data from an environment. Backpropagation appears to be biologically implausible, yet is very effective in deep learning. Humans need far fewer samples to learn from compared to deep learning models. Adversarial attacks against deep learning models appear similar to optical illusions for humans. Deep learning models inherit bias from data, which has some intriguing implications for the empiricism analogy. Philosophical normativity might be able to provide moral guidelines for building AI. DNNs are compatible with a mechanistic view on cognition.