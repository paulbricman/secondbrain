---
---

Each [[Eigenvectors are scaled by eigenvalues in linear transformation|linear transformation]] can be expressed as a matrix. The column vectors of the matrix stand for the new locations of the [[One-hot encodings are basis vectors in type space|initial basis vectors]]. Matrices capture most parameters of a linear layer in [[Supervised learning assumes underlying structure|supervised learning]].