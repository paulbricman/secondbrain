---
resource: https://www.ai.rug.nl/minds/uploads/LN_NN_RUG.pdf
---

While the L1, L2 norms, and p-norm in general are [[Optimizing for short semantic distances fosters learning|distance functions]] which take into consideration the magnitude of the two [[One-hot encodings are basis vectors in type space|vectors]] involved, cosine similarity only indicates how well the two vectors are aligned in space, regardless of their magnitude. Cosine similarity is the default choice in [[Multi-lingual embeddings formalize geography of thought|word embeddings]].