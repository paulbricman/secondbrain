---
resource: https://www.ai.rug.nl/minds/uploads/LN_NN_RUG.pdf
---

While the L1, L2 norms, and p-norm in general are [[Optimizing for short semantic distances fosters learning|distance functions]] which take into consideration the magnitude of the two [[One-hot encodings are basis vectors in type space|vectors]] involved, the cosine similarity only indicates how aligned are the two, regardless of their magnitude. Cosine similarity is the default choice in [[Multi-lingual embeddings formalize geography of thought|word embeddings]].