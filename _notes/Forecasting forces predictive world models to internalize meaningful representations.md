---
resource: https://www.youtube.com/watch?v=o75ybZ-6Uu8
---

A simple way to force a machine learning model to derive a meaningful representation about the world it lives in is by tasking it to predict the short-term future. If a model successfully manages to predict how its environment unfolds in the future, then it plausibly learned a great deal about its inner workings. This can be seen as a [[Self-supervised learning approximates commonsense|self-supervised learning paradigm]], together with [[Recovery and matching provide self-supervised signals|recovery and matching]]. Additionally, attempting to predict one's behavior might lead to a meaningful representation of their [[Digital twins expose physical objects to digital manipulations|behavior]].