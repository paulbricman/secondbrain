---
resource: https://openai.com/blog/clip/
---

Using a [[Multi-modal mappings generate multi-modal receptive fields|multi-modal encoder]], one can embed, say, [[Description and depiction are interconnected|both texts and images]] in a joint [[Latent spaces have both continuous and discrete properties|latent space]]. This makes it so that all [[Spatial metaphors provide primitives for latent space navigation|primitives for latent space navigation]] can be enriched using multi-modal guidance. For instance, the semantic field of a text can yield images, and multi-modal [[Metaphor is central to cognition|analogies]] can be resolved. When specific manipulations are needed, the items can be stored in the most suitable representation.