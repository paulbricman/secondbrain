---
resource: https://www.ai.rug.nl/minds/uploads/LN_NN_RUG.pdf
---

In reinforcement learning, as opposed to [[Supervised learning assumes underlying structure|supervised learning]], [[Localized secretive agents create buffer zones|agents]] are tasked with coming up with a strategy, a policy for [[Darwinism infuses enaction with realism|acting in their world]]. Often, this is done by augmenting [[Finite-state dynamical systems are diverse|finite-state dynamical systems with a notion of reward]]. This is done by attaching a reward to each [[Dynamical systems have a certain anatomy|transition]], and describing a successful policy one that maximizes the [[Extrinsic reward dependence is unsustainable|received reward]] in the long run.