---
resource: https://www.ai.rug.nl/minds/uploads/LN_NN_RUG.pdf
---

In [[Supervised learning assumes underlying structure|supervised learning]], simple perceptrons have been shown to be able to [[Regularization penalizes flexibility|accurately describe an extremely broad family of functions]]. However, they would need an extremely wide single layer to do this, sometimes even larger than there are atoms in the universe, making it unfeasible to train. In light of this [[Deep learning enables simple chained transformations|deep learning is more economical]].