If you fine-tune a language model on a specific type of text, say for [[Conversational interfaces render knowledge bases into agents|creating conversational agents which resemble one's style]], it will inevitably decrease in performance on other texts. This might also apply to [[Tools for thought scarcely internalize externalities|tools for thought]] and [[Pleiotropy challenges adaptationism|pleiotropy]].