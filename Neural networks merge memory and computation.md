The von Neumann architecture marks a clear distinction between memory and computation. This, however, leads to the von Neumann bottleneck, because information has to continuously be brought back and forth between memory components and computational compontents. In contrast, neural networks merge memory and computation by design. Their parameters house predefined representations, yet inference enables then to support computation.